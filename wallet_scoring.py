# -*- coding: utf-8 -*-
"""wallet_scoring.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Efub9Y3BKagmSMOVbZOT--U0LdmbJsn
"""

import requests
import pandas as pd

API_KEY = 'TGWFT5C35AE2BPPEYIWN26IXVKIJ6UVGTD'

def fetch_transactions(wallet_address):

    url= f'https://api.etherscan.io/api?module=account&action=txlist&address={wallet_address}&startblock=0&endblock=99999999&sort=asc&apikey={API_KEY}'
    response=requests.get(url)
    data =response.json()

    if data['status']=='1':
        return data['result']
    else:
        return []

# testing first with one wallet address
wallet = '0xfaa0768bde629806739c3a4620656c5d26f44ef2'
txs = fetch_transactions(wallet)

df = pd.DataFrame(txs)
df.to_csv('wallet_tx_history.csv', index=False)
print(f"Total transactions fetched: {len(df)}")

#getting started with all the wallet ids from the given csv file
wallets_df =pd.read_csv('Wallet id - Sheet1.csv')
all_wallets =wallets_df['wallet_id'].tolist()

# for storing the transaction information
all_data = []

#getting transaction details for all the wallets and saving it in a csv file
import time
for idx, wallet in enumerate(all_wallets) :

    print(f"Loading wallet {idx+1} / {len(all_wallets)}:{wallet}")
    txs=fetch_transactions(wallet)

    for tx in txs:
        tx['wallet_id']=wallet
    all_data.extend(txs)

    time.sleep(0.3) # pausing as the etherscan api allows only 3 calls per second


all_df = pd.DataFrame(all_data)
all_df.to_csv('all_wallets_transactions.csv',index=False)
print(f"\n Total transactions collected:{len(all_df)}")

"""**Preprocessing the data by filtering compound-specific transactions**"""

df = pd.read_csv('all_wallets_transactions.csv')
df.columns = df.columns.str.lower()

# Compound V2 + V3 contract addresses

compound_signatures = [
    '0xc5ebeaec',
    '0x0e752702',
    '0xa0712d68',
    '0xdb006a75',
    '0x852a12e3',
    '0xf5e3c462',
    '0xc2998238',
]
# Filtering if input starts with any of them
def is_compound_input(input_str):

    return any(input_str.startswith(sig) for sig in compound_signatures)

df['is_compound']=df['input'].apply(is_compound_input)


compound_contracts = [

    '0x4ddc2d193948926d02f9b1fe9e1daa0718270ed5',
    '0x39aa39c021dfbae8fac545936693ac917d5e7563',
    '0x5d3a536e4d6dbd6114cc1ead35777bab948e3643',
    '0xf650c3d88cc861efdb9ee8315e69d6a3b6498d6e',
    '0xccf4429db6322d5c611ee964527d42e5d685dd6a',
    '0x35a18000230da775cac24873d00ff85bccded550',
    '0x3d9819210a31b4961b30ef54be2aed79b9c9cd3b',
    '0xc3d688b66703497daa19211eedff47f25384cdc3',
    '0xa17581a9e3356d9a858b789d68b4d866e593ae94',
    '0xd226392c23fb3476274ed6759d4a478db3197d82',
]

df['to']=df['to'].astype(str).str.lower()
df['is_compound_to']= df['to'].isin(compound_contracts)

#filtering transactions and saving them
compound_df =df[(df['is_compound']) | (df['is_compound_to'])]

compound_df.to_csv('compound_wallet_transactions.csv', index= False)
print(f"Total compound related transactions:{len(compound_df)}")

"""**Getting started with Feature Engineering by extracting meaninfdul features that reflect user behaviour and risk from compound related transactions**"""

df = pd.read_csv('compound_wallet_transactions.csv')
df.columns = df.columns.str.lower()

# Handling missing or invalid types

df['value'] =pd.to_numeric(df['value'],errors= 'coerce')
df['gasused'] =pd.to_numeric(df['gasused'], errors= 'coerce')
df['input'] =df['input'].astype(str).str.lower()

# Classifying transactions by input signature
def classify_tx_type(input_data):
    if input_data.startswith('0xc5ebeaec'):
        return 'borrow'

    elif input_data.startswith('0x0e752702'):
        return 'repay'
    elif input_data.startswith('0xa0712d68'):
        return 'mint'

    elif input_data.startswith('0xdb006a75') or input_data.startswith('0x852a12e3'):
        return 'redeem'

    elif input_data.startswith('0xf5e3c462'):
        return 'liquidate'
    elif input_data.startswith('0xc2998238'):
        return 'enter_market'

    else:
        return 'other'

df['action_type'] =df['input'].apply(classify_tx_type)

#Aggregrating the features by wallet

features= df.groupby('wallet_id').agg(

    compound_tx_count=('hash', 'count'),

    avg_gas_used=('gasused', 'mean'),
    max_value_transacted=('value', 'max'),

    unique_contracts=('to', pd.Series.nunique)
).fillna(0)

action_counts = df.pivot_table(index='wallet_id', columns='action_type', aggfunc='size', fill_value=0)

features = features.join(action_counts, how='left').fillna(0)

features['borrow_to_repay_ratio'] = features.apply(
    lambda row: row['borrow'] / row['repay'] if row['repay'] > 0 else 10, axis=1
)

features.reset_index(inplace=True)
features.to_csv('wallet_features.csv',index=False)

print(f"Engineered features for {len(features)} wallets.")

"""**Establishing the Scoring Model**"""

from sklearn.preprocessing import MinMaxScaler
df = pd.read_csv('wallet_features.csv')
df.fillna(0, inplace=True)

#selecting the features that will give the scoring
scoring_features = [
    'borrow_to_repay_ratio',
    'compound_tx_count',
    'max_value_transacted',
    'avg_gas_used',
    'borrow',
    'repay'
]

# normalizing by using min-max scaling
scaler =MinMaxScaler()
df_scaled =pd.DataFrame(scaler.fit_transform(df[scoring_features]),columns=[f'{f}_norm' for f in scoring_features])

df=pd.concat([df, df_scaled],axis=1)

# Assign weights to each feature to control their influence on the score

df['risk_score'] = (
    df['borrow_to_repay_ratio_norm'] * 0.3+
    (1 -df['compound_tx_count_norm']) * 0.1+
    df['max_value_transacted_norm'] *0.2 +
    df['avg_gas_used_norm'] * 0.1 +
    df['borrow_norm'] * 0.2+
    (1 -df['repay_norm']) *0.1
)

# scaling the score to be between 0-1000 as per the problem statement
df['risk_score']=(df['risk_score'] -df['risk_score'].min()) / (df['risk_score'].max() -df['risk_score'].min())
df['risk_score'] =(df['risk_score']*1000).round(2)

df[['wallet_id','risk_score']].to_csv('wallet_risk_scores.csv',index=False)
print("Risk scores generated")

"""**An additional visualization for the riskiest wallets**"""

import matplotlib.pyplot as plt
import seaborn as sns

df =pd.read_csv('wallet_risk_scores.csv')
top_risk= df.sort_values(by='risk_score', ascending=False).head(10)

plt.figure(figsize=(12, 6))
sns.barplot(data=top_risk, x='wallet_id', y='risk_score', hue='wallet_id', palette='Reds_r', legend=False)
plt.title('Top 10 Riskiest Wallets', fontsize=14)
plt.xlabel('Wallet ID')
plt.ylabel('Risk Score')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig('top_10_riskiest_wallets.png')
plt.show()